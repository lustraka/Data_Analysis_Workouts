{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISL02 Statistical Learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgu7ka9H1C3J95bnlU6vi3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lustraka/Data_Analysis_Workouts/blob/main/Introduction_to_Statistical_Learning/ISL02_Statistical_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRpt8ev1BOtb"
      },
      "source": [
        "# Statistical Learning\n",
        "## What is Statistical Learning?\n",
        "![Key Concepts](http://www.plantuml.com/plantuml/png/RP5BImD13CVl_HGvjYobTrbAGKHlYWXU2fBEPBV1UQoPR1-8tzt8h1Inbmd9_vS7yzyKHT78oKSSPWtS5UM8Ij06Uq_hxHxri_jgLpMTDGsyxiyMcZSOX3mxvPngpgaZeUJ8KdZ8nub2mKWgxC32FljIwocdvLKDNWGzBH-xhe8nUmesN4bie-AE0-k_4m2T6mNT6UPTe1DNQc4Ot8_iiPvbBMKSI0vSo4CWbCIfhyAOhalm97aNA4vtFrClLChFold7Y4bPKVb0ODKXfqABojq6DAfZP-h4XbyKtn6iJdqMqyEbTPlcBQztT4IX6mYvP_F3WLnsSW44ztTs_RjsnUl5R4DcPRNp6m00)\n",
        "\n",
        "Suppose that we observe a quantitative response $Y$ and $p$ different predictors, $X_1, X_2,...,X_p$. We assume that there is some relationship between $Y$ and $X = (X_1, X_2,...,X_p)$, which can be written in the very general form\n",
        "\n",
        "$$Y = f(X) + \\epsilon. \\qquad (1)$$\n",
        "\n",
        "Here $f$ is some fixed but unknown funtion of $X_1, X_2,...,X_p$, and $\\epsilon$ is a random *error term*, which is independent of $X$ and has mean zero. In this formulation, $f$ represents the *systematic* information that $X$ provides about $Y$.\n",
        "\n",
        "### Why Estimate $f$ ?\n",
        "There are two main reasons that we may wish to estimate $f$ : *prediction* and *inference*.\n",
        "\n",
        "**Predicion**. In many situations a set of inputs $X$ are readily available, but the output $Y$ cannot be easily obtained. In this setting, since the error term averages to zero, we can predict $Y$ using\n",
        "\n",
        "$$\\hat{Y} = \\hat{f}(X), \\qquad (2)$$\n",
        "\n",
        "where $\\hat{f}$ represents our estimate of $f$, and $\\hat{Y}$ represents the resulting prediction for $Y$. In this setting, $\\hat{f}$ is often treated as a *black box*, in the sense that one is not typically concerned with the exact form of $\\hat{f}$, provided it yields accurate predictions for $Y$.\n",
        "\n",
        "Consider a given estimate $\\hat{f}$ and a set of predictors $X$, which yields the prediction $\\hat{Y} = \\hat{f}(X)$. Assume for a moment that both $\\hat{f}$ and $X$ are fixed, so that only variability comes from $\\epsilon$. Then, it is easy to show that\n",
        "\n",
        "$$E(Y - \\hat{Y})^2 = E[f(X) + \\epsilon - \\hat{f}(X)]^2 = \\underbrace{[f(X) - \\hat{f}(X)]^2}_\\text{Reducible} + \\underbrace{\\text{Var}(\\epsilon)}_\\text{Irreducible}, \\quad (3)$$\n",
        "\n",
        "where $E(Y - \\hat{Y})^2$ represents the average, or *expected value*, of the squared difference between the predicted and actual value of $Y$, and $\\text{Var}(\\epsilon)$ represents the *variance* associated with the error term $\\epsilon$.\n",
        "\n",
        "> The focus of this repository is on techniques for estimating $f$ with the aim of minimizing the reducible error. It is important to keep in mind that the irreducible error will always provide the upper bound on the accuracz of our prediction on $Y$. This bound is almost always unknown in practice.\n",
        "\n",
        "**Inference**. We are often interested in understanding the association between $Y$ and $X_1, X_2,...,X_p$. In this situation we wish to estimate $f$, but our goal is not necessarily to make predictions for $Y$. Now $\\hat{f}$ cannot be treated as a black box, because we need to know its exact form. In this setting, one may be interested in answering the following questions:\n",
        "- Which predictors are associated with the response?\n",
        "- What is the relationship between the response and each predictor?\n",
        "- Can the relationship between $Y$ and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?\n",
        "\n",
        "> In this repository, we will see a number of examples that fall into the prediction setting, the inference setting, or a combination of the two.\n",
        ">\n",
        "> Depending on whether our ultimate goal is prediction, inference, od a combination of the two, different methods for estimating $f$ may be appropriate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV3HPh8DTvfC"
      },
      "source": [
        "### How Do We Estimate $f$ ?\n",
        "**Parametric Methods** involve two-step model-based approach.\n",
        "1. First, we make an assumption about the functional form, or shape, of $f$. For example, one very simple assumption is that $f$ is linear in $X$:\n",
        "$$f(X) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p. \\qquad (4)$$\n",
        "This is a *linear model*. Once we have assumed tha $f$ is linear, the problem of estimating $f$ is greatly simplified. Instead of having to estimate an entirely arbitrary $p$-dimensinal function $f(X)$, one only needs to estimate $p+1$ coefficients $\\beta_0, \\beta_1, ..., \\beta_p$.\n",
        "\n",
        "2. After a model has been selected, we need a procedure that uses the training data to *fit* or *train* the model. In case of the linear model $(4)$, we need to estimate the parameters $\\beta_0, \\beta_1, ..., \\beta_p$. That is, we want to find values of these parameters such that\n",
        "$$Y \\approx \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p.$$\n",
        "The most common approach to fitting the model $(4)$ is referred to as *(ordinary) least squares*, but there are also other approaches.\n",
        "\n",
        "**Non-Parametric Methods** do not make explicit assumptions about the functional form of $f$. Instead they seek an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly. An example is a *thin-plate spline*. In order ro fit a thin-plate spline, the data analyst must select a level of smoothness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuLtGT4DX7aB"
      },
      "source": [
        "### The Trade-Off Between Prediction Accuracy and Model Interpretability\n",
        "In general, as the flexibility of a method increases, its interpretability decreases.\n",
        "\n",
        "### Supervised Versus Unsupervised Learning\n",
        "\n",
        "**Supervised Learning**. For each observation of the predictor measurement(s) $x_i, i = 1, ..., n$ there is an associated response measurement $y_i$. We wish to fit a model that relates the response to the predictors, with the aim of accurately predicting the response for future observation (prediction) or better understand the relationship between the response and the predictors (inference).\n",
        "\n",
        "**Unsupervised Learning** describes somewhat more challenging situation in which for every observation $i = 1, ..., n$, we observe a vector of measurements $x_i$ but no associated response $y_i$. One statistical tool that we may use in this setting is *cluster analysis*, or clustering. The goal of cluster analysis is to ascertain, on the basis of $x_1, ..., x_n$, whether the observation fall into relatively distict groups.\n",
        "\n",
        "### Regression Versus Classification Problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBM2ZNqKbJVP"
      },
      "source": [
        "## Assessing Model Acuracy\n",
        "### Measuring the Quality of Fit\n",
        "\n",
        "### Tha Bias-Variance Trade-Off\n",
        "\n",
        "### The Classification Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVNtE_TITuiM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPQQgUtrivAY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHBbuDhb3jzy"
      },
      "source": [
        "---\n",
        "![Expected Value](http://www.plantuml.com/plantuml/png/SoWkIImgoKqioU1orOXKq5M8oKWigOwirOmpKh1LS8rEquZGLD1MY4ajACxCoS-3AKYh1Oh7WjN4bEQbf1Ob5IKcfrQ3bQEhgOsFAKcjAAaEIaqfJSvCoacjLT16qGMH3aiigjM0sQC9q-HPL0JNfgCGKrYQcAAWOQp9vP2Qbm9oDG00)"
      ]
    }
  ]
}